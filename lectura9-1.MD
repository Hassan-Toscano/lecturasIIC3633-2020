Artículo: Multi-armed recommender system bandit ensembles                               Nombre: Jasiel Hassan Toscano Martinez

Resumen: Anteriormente los algoritmos de recomendación eran probados y comparados en una única ejecución no interactiva, donde se entregaba a cada uno de los usuarios solo un conjunto de recomendaciones, para posteriormente calcular una métrica de evaluación. En este trabajo se propone considerar una perspectiva más realista que consiste en integrar la naturaleza cíclica de la terea de la recomendación en donde una parte de la entrada del sistema se recopila a partir de la reacción de los usuarios.
En este trabajo se realiza la adaptación del enfoque de bandidos con múltiples brazos para construir conjuntos de sistemas de recomendación, donde los algoritmos de recomendación son representados como brazos que se combinan en el conjunto y el conjunto como un bandido que en cada interacción selecciona un brazo para producir la siguiente ronda de recomendaciones

Comentarios: En este trabajo se adaptaron dos algoritmos de bandidos que se basan en el muestreo de thompson y ε-codicioso. Además, el conjunto de datos MovieLens se utilizó para verificar el desempeño de los conjuntos recomendadores de bandidos. Los algoritmos de recomendación para medir el comportamiento son: dos métodos de filtrado colaborativo y la recomendación más popular no personalizadas y un conjunto dinámico alternativo que se aplica a los 3 anteriores algoritmos recomendadores.
En la evaluación los usuarios realizan la puntuación de los elementos que se recomiendan de una forma iterativa por parte de los sistemas de recomendación. Esta puntuación es usada como entrada para producir la siguiente ronda de recomendaciones.

Crítica: Una de las principales desventajas que se pueden observar se basa en que cada sistema de recomendación se construye a partir de las puntuaciones y sus propias recomendaciones, es decir, únicamente comparten la base de entrenamiento inicial.
Los algoritmos de bandidos presentan un buen rendimiento. Los resultados señalan que la recomendación más popular domina en las primeras iteraciones debido a la vulnerabilidad a la escases de datos iniciales de los algoritmos de filtrado colaborativo. Una vez transcurridas las primeras iteraciones se puede observar que el método de la factorización matricial comienza a ganar terreno. Por último, una desventaja importante se basa en que el conjunto de bandidos tarde o temprano terminara favoreciendo a la factorización matricial debido a que se va recopilando datos más enriquecidos en relación a las preferencias de los usuarios

Referencia: Cañamares R., Redondo M., and Castells P., “Multi-armed recommender system bandit ensembles”, RecSys'19 Proceedings of the 13th ACM conference on recommender systems, pp. 432-436, 2019. DOI: 10.1145/3298689.3346984
